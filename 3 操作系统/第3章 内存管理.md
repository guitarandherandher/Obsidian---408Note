# 3.1 内存管理概念

## 内存的基础知识

![内存的基础知识.pdf](附件/01.3.1.1_1%20内存的基础知识.pdf)

### 什么是内存，有何作用

内存可存放数据。程序执行前**需要先放到内存中才能被CPU处理**——缓和CPU与硬盘之间的速度矛盾

思考：在多道程序环境下，系统中会有多个程序并发执行，也就是说会有多个程序的数据需要同时放到内存中。那么，如何区分各个程序的数据是放在什么地方的呢？
方案：给内存的存储单元编地址，如按字节编址或按字编址

### 进程运行的基本原理

#### 指令的工作原理

程序经过编译、链接后生成的指令中指明的是**逻辑地址**（相对地址），即：相对于进程的起始地址而言的地址

#### 从写程序到程序运行

1. **编译**：由编译程序将用户源代码编译成若干个目标模块（编译就是把高级语言翻译为机器语言）
2. **链接**：由链接程序将编译后形成的一组目标模块，以及所需库函数链接在一起，形成一个完整的装入模块——确定逻辑地址
3. **装入**：由装入程序将装入模块装入内存运行——确定物理地址

#### 链接的三种方式

* **静态链接**：将目标模块在装入前链接成一个完整的装配模块，再将其装入内存。
* **装入时动态链接**：将目标模块一边装入内存一边进行链接。
* **运行时动态链接**：在程序执行过程中需要用到某一目标模块时，再将该模块调入内存进行链接。

#### 装入的三种方式

1. 绝对装入
2. 可重定位装入（静态重定位）
3. 动态运行时装入（动态重定位）

* **绝对装入**：预先知道装入位置，在编译过程中就将逻辑地址转换为物理地址。装入程序按照装入模块中的地址，将程序和数据装入内存。
	* 绝对装入只适用于单道程序环境。（还没产生操作系统，由编译器完成）
	* 程序中使用的绝对地址，可在编译或汇编时给出，也可由程序员直接赋予。<u>通常情况下都是编译或汇编时再转换为绝对地址。</u>

**静态重定位**：又称可重定位装入。编译、链接后的装入模块的地址都是从0开始的，指令中使用的地址、数存放的地址都是<u>相对于起始地址而言的逻辑地址</u>。可根据内存的当前情况，将装入模块装入到内存的适当位置。装入时对地址进行“重定位”，将逻辑地址变换为物理地址（<u>地址变换是在装入时一次完成的</u>）。

静态重定位的特点是在一个作业装入内存时，<u>必须分配其要求的全部内存空间</u>，如果没有足够的内存，就不能装入该作业。作业一旦进入内存后，<u>在运行期间就不能再移动</u>，也不能再申请内存空间。（用于早期的多道批处理操作系统）

**动态重定位**：又称动态运行时装入。编译、链接后的装入模块的地址都是从0开始的。装入程序把装入模块装入内存后，并不会立即把逻辑地址转换为物理地址，而是<u>把地址转换推迟到程序真正要执行时才进行</u>。因此装入内存后所有的地址依然是逻辑地址。这种方式需要一个**重定位寄存器**的支持。

采用动态重定位时允许程序在内存中发生移动。并且可将程序分配到不连续的存储区中；在程序运行前只需装入它的部分代码即可投入运行，然后在程序运行期间，根据需要动态申请分配内存；便于程序段的共享，可以向用户提供一个比存储空间大得多的地址空间。（现代操作系统）

## 3.1.1 内存管理的基本原理和要求

![内存管理的概念.pdf](附件/02.3.1.1_2%20内存管理的概念.pdf)

* 操作系统负责<u>内存空间的分配与回收</u>
	* 连续分配方式
		* [单一连续分配](#单一连续分配)
		* [固定分区分配](#固定分区分配)
		* [动态分区分配](#动态分区分配)
	* 非连续分配管理方式
		* [基本分页存储管理](#3.1.4%20基本分页存储管理)
		* [基本分段存储管理](#3.1.5%20基本分段存储管理)
		* [段页式存储管理](#3.1.6%20段页式管理)
* 操作系统需要提供某种技术从<u>逻辑上对内存空间进行扩充</u>（操作系统的虚拟性）
	* [覆盖技术](#覆盖技术)
	* [交换技术](#交换技术)
	* [虚拟存储技术](#3.2%20虚拟内存管理)
* 操作系统需要提供地址转换功能，负责程序的[<u>逻辑地址与物理地址的转换</u>](#装入的三种方式)
* 操作系统需要提供<u>内存保护功能</u>，保证各进程在各自存储空间内运行，互不干扰
* 操作系统需要提供<u>内存共享功能</u>，当多个进程共用同一程序文件时，只在内存中保留一个副本，并让共享进程都能访问这一部分内存。

#### 内存保护

内存保护由操作系统和硬件机构共同完成。可采取两种方法：

* 方法一：在CPU中设置一对**上、下限寄存器**，存放进程的上、下限地址。进程的指令要访问某个地址时，CPU检查是否越界
* 方法二：采用**重定位寄存器**（又称**基址寄存器**）和**界地址寄存器**（又称**限长寄存器**）进行越界检查。
	* 重定位寄存器中存放的是进程的起始物理地址。
	* 界地址寄存器中存放的是进程的最大逻辑地址。

![第3章-内存保护.drawio](图表/第3章-内存保护.drawio.svg)

## 3.1.2 覆盖与交换

> 内存空间的扩充有以下几种方式：
>
> * [覆盖技术](#覆盖技术)
> * [交换技术](#交换技术)
> * [虚拟存储技术](#3.2%20虚拟内存管理)

![覆盖与交换.pdf](附件/03.3.1.2%20覆盖与交换.pdf)

### 覆盖技术
> 同一程序或进程中

覆盖技术的思想：将程序分为多个段（多个模块）。常用的段常驻内存，不常用的段在需要时调入内存。内存中分为一个“固定区”和若干个“覆盖区”。

* 需要常驻内存的段放在“**固定区**”中，调入后就不再调出（除非运行结束）
* 不常用的段放在“**覆盖区**”，需要用到时调入内存，用不到时调出内存。按照自身逻辑结构，让那些不可能同时被访问的程序段共享同一个覆盖区
* 由程序员声明覆盖结构，操作系统完成自动覆盖。

缺点：对用户不透明，增加了用户编程负担。覆盖技术只用于早期的操作系统中，现在已成为历史。

### 交换技术
> 不同进程或作业之间

交换（对换）技术的设计思想：内存空间紧张时，系统将内存中某些进程暂时**换出外存**，把外存中某些已具备运行条件的进程**换入内存**（进程在内存与磁盘间动态[调度](./第2章%20进程与线程#中级调度（内存调度）)）

注意：PCB会常驻内存，不会被换出外存（为了管理换出外存的进程）

暂时换出外存等待的进程状态为**挂起状态**，挂起态又可以进一步细分为就绪挂起、阻塞挂起两种状态（[七状态模型](./第2章%20进程与线程#补充知识：进程的挂起态与七状态模型)）

**应该在外存（磁盘）的什么位置保存被换出的进程？**

具有对换功能的操作系统中，通常把磁盘空间分为文件区和对换区两部分，对换区的I/O速度比文件区的更快。

* **文件区**主要用于存放文件，<u>主要追求存储空间的利用率</u>，因此对文件区空间的管理采用离散分配方式；
* **对换区**空间只占磁盘空间的小部分，被换出的进程数据就存放在对换区。由于对换的速度直接影响到系统的整体速度，因此对换区空间的管理<u>主要追求换入换出速度</u>，因此通常对换区采用[连续分配方式](第4章%20文件管理系统#连续分配)

**什么时候应该交换？**

交换通常在许多进程运行且内存吃紧时进行，而系统负荷降低就暂停。例如：

* 在发现许多进程运行时经常发生缺页，就说明内存紧张，此时可以换出一些进程；
* 如果缺页率明显下降，就可以暂停换出。

**应该换出哪些进程？**

* 可优先换出阻塞进程；
* 可换出优先级低的进程；
* 为了防止优先级低的进程在被调入内存后很快又被换出，有的系统还会考虑进程在内存的驻留时间…
* 当一个进程正在I/O操作时，不能交换出主存

## 3.1.3 连续分配管理方式

![连续分配管理方式.pdf](附件/04.3.1.3_1%20连续分配管理方式.pdf)

连续分配：指为用户进程分配的必须是一个连续的内存空间。

|                                       | [单一连续分配](#单一连续分配) | [固定分区分配](#固定分区分配) | [动态分区分配](#动态分区分配) |
| :-----------------------------------: | :---------------: | :---------------: | :---------------: |
|  外部碎片^[**外部碎片**：内存中的某些空闲分区由于太小而难以利用]  |                   |                   |         √         |
| 内部碎片^[**内部碎片**：分配给某进程的内存区域中，有些部分没有用上] |         √         |         √         |                   |

### 单一连续分配

在单一连续分配方式中，内存被分为系统区和用户区。

* **系统区**通常位于内存的低地址部分，用于存放操作系统相关数据；
* **用户区**用于存放用户进程相关数据。

<u>内存中只能有一道用户程序，用户程序独占整个用户区空间</u>。

* 优点：实现简单；无外部碎片；可以采用覆盖技术扩充内存；不一定需要采取内存保护（eg：早期的PC操作系统MS-DOS）。
* 缺点：只能用于单用户、单任务的操作系统中；有内部碎片；存储器利用率极低。

### 固定分区分配

20世纪60年代出现了支持多道程序的系统，为了能在内存中装入多道程序，且这些程序之间又不会相互干扰，于是<u>将整个用户空间划分为若干个固定大小的分区</u>，在每个分区中只装入一道作业，这样就形成了最早的、最简单的一种可运行多道程序的内存管理方式。

固定分区分配有两种方式

* **分区大小相等**：缺乏灵活性，但是很适合用于用一台计算机控制多个相同对象的场合（比如：钢铁厂有 $n$ 个相同的炼钢炉，就可把内存分为 $n$ 个大小相等的区域存放 $n$ 个炼钢炉控制程序）
* **分区大小不等**：增加了灵活性，可以满足不同大小的进程需求。根据常在系统中运行的作业大小情况进行划分（比如：划分多个小分区、适量中等分区、少量大分区）

操作系统需要建立一个数据结构——**分区说明表**，来实现各个分区的分配与回收。每个表项对应一个分区，通常按分区大小排列。每个表项包括对应分区的<u>大小、起始地址、状态（是否已分配）</u>。

当某用户程序要装入内存时，由操作系统内核程序根据用户程序大小检索该表，从中找到一个能满足大小的、未分配的分区，将之分配给该程序，然后修改状态为“已分配”。

* 优点：实现简单，无外部碎片。
* 缺点：
	* 当用户程序太大时，可能所有的分区都不能满足需求，此时不得不采用覆盖技术来解决，但这又会降低性能；
	* 会产生内部碎片，内存利用率低。

### 动态分区分配

动态分区分配又称为可变分区分配。这种分配方式不会预先划分内存分区，而是在<u>进程装入内存时，根据进程的大小动态地建立分区，并使分区的大小正好适合进程的需要</u>。因此系统分区的大小和数目是可变的。

**系统要用什么样的数据结构记录内存的使用情况？**

* **空闲分区表**：每个空闲分区对应一个表项。表项中包含分区号、分区大小、分区起始地址等信息（不一定按照地址递增顺序排列，具体的排列方式需要依照动态分区分配算法来确定）
* **空闲分区链**：每个分区的起始部分和末尾部分分别设置前向指针和后向指针。起始部分处还可记录分区大小等信息

**当很多个空闲分区都能满足需求时，应该选择哪个分区进行分配？**

* 把一个新作业装入内存时，须按照一定的[**动态分区分配算法**](#动态分区分配算法)，从空闲分区表（或空闲分区链）中选出一个分区分配给该作业。

**如何进行分区的分配与回收操作？**

* 相邻的空闲区间需要合并
* 动态分区分配没有内部碎片，但是有外部碎片。
* 如果内存中空闲空间的总和本来可以满足某进程的要求，但由于进程需要的是一整块连续的内存空间，因此这些“碎片”不能满足进程的需求。可以通过**紧凑**（拼凑）技术来解决外部碎片。

---

### 动态分区分配算法

> 在动态分区分配方式中，当很多个空闲分区都能满足需求时，应该选择哪个分区进行分配？

![动态分区分配算法.pdf](附件/05.3.1.3_2%20动态分区分配算法.pdf)

#### 首次适应算法(First Fit)

> 从头开始，使用第一个满足要求的空闲分区

算法思想：每次都从低地址开始查找，找到第一个能满足大小的空闲分区。

如何实现：空闲分区以地址递增的次序排列。<u>每次分配内存时顺序查找空闲分区链（或空闲分区表），找到大小能满足要求的第一个空闲分区</u>。

特点：
* 算法开销小，回收分区后，一般不需要对空闲分区队列重新排序
* 每次都要从头查找，每次都需要检索低地址的小分区。但是这种规则也决定了当低地址部分有更小的分区可以满足需求时，会更有可能用到低地址部分的小分区，也会更有可能把高地址部分的大分区保留下来（最佳适应算法的优点）

**综合来看，四种算法中，首次适应算法的效果反而更好**

#### 邻近适应算法(Next Fit)

> 从上次结果开始，使用第一个满足要求的空闲分区

算法思想：首次适应算法每次都从链头开始查找的。这可能会导致低地址部分出现很多小的空闲分区，而每次分配查找时，都要经过这些分区，因此也增加了查找的开销。如果每次都从上次查找结束的位置开始检索，就能解决上述问题。

如何实现：空闲分区以地址递增的顺序排列（可排成一个循环链表）。<u>每次分配内存时从上次查找结束的位置开始查找空闲分区链（或空闲分区表），找到大小能满足要求的第一个空闲分区</u>。

* 优点：不用每次都从低地址的小分区开始检索，算法开销小
* 缺点：可能会导致无论低地址、高地址部分的空闲分区都有相同的概率被使用，也就导致了高地址部分的大分区更可能被使用，划分为小分区，最后导致无大分区可用

#### 最佳适应算法(Best Fit)

> 优先使用更小的连续空闲区

算法思想：由于动态分区分配是一种连续分配方式，为各进程分配的空间必须是连续的一整片区域。因此为了保证当“大进程”到来时能有连续的大片空间，可以尽可能多地留下大片的空闲区，即，优先使用更小的空闲区。

如何实现：空闲分区按容量递增次序链接。每次分配内存时顺序查找空闲分区链（或空闲分区表），找到大小能满足要求的第一个空闲分区。

缺点：
* 每次都选最小的分区进行分配，会留下越来越多的、很小的、难以利用的内存块。因此这种方法会产生很多的外部碎片；
* 算法开销大，回收分区后需要对空闲分区队列重新排序

#### 最坏适应算法(Worst Fit)

> 优先使用最大的连续空闲区

又称最大适应算法（Largest Fit）

算法思想：为了解决最佳适应算法的问题——即留下太多难以利用的小碎片，可以在每次分配时优先使用最大的连续空闲区，这样分配后剩余的空闲区就不会太小，更方便使用。

如何实现：空闲分区按容量递减次序链接。每次分配内存时顺序查找空闲分区链（或空闲分区表），找到大小能满足要求的第一个空闲分区。

缺点：
* 每次都选最大的分区进行分配，虽然可以让分配后留下的空闲区更大，更可用，但是这种方式会导致较大的连续空闲区被迅速用完。如果之后有“大进程”到达，就没有内存分区可用了；
* 算法开销大，回收分区后需要对空闲分区队列重新排序

## 3.1.4 基本分页存储管理

### 分页存储的基本概念

![基本分页存储管理的基本概念.pdf](附件/06.3.1.4_1%20基本分页存储管理的基本概念.pdf)

#### 分页存储

* <u>将内存空间分为一个个大小相等的分区</u>（比如：每个分区4KB），每个分区就是一个“**页框**”（页框=页帧=内存块=物理块=物理页面）。每个页框有一个编号，即“**页框号**”（页框号=页帧号=内存块号=物理块号=物理页号），页框号从0开始。
* <u>将进程的逻辑地址空间也分为与页框大小相等的一个个部分</u>，每个部分称为一个“**页**”或“页面”。每个页面也有一个编号，即“**页号**”，页号也是从0开始。<!--初学易混：页、页面vs页框、页帧、物理页页号、页面号vs页框号、页帧号、物理页号-->
* <u>操作系统以页框为单位为各个进程分配内存空间</u>。进程的每个页面分别放入一个页框中。也就是说，进程的页面与内存的页框有一一对应的关系。各个页面不必连续存放，可以放到不相邻的各个页框中。
* 进程的最后一个页面可能没有一个页框那么大。也就是说，分页存储有可能产生内部碎片，因此页框不能太大，否则可能产生过大的内部碎片造成浪费

#### 页表

为了能知道进程的每个页面在内存中存放的位置，操作系统要为<u>每个进程建立一张页表</u>。页表通常存在[PCB](./第2章%20进程与线程#PCB)中

* 一个进程对应一张页表，页表记录进程页面和实际存放的内存块之间的映射关系
* 进程的每个页面对应一个**页表项**，逻辑上页表项由“**页号**”和“**块号**”组成，所有页表项长度相等。其中因为页表项连续存放，故页号是隐含的，不占用空间； 而块号长度与内存块数量有关（内存→内存块数量→内存块中块号所占字节）
* 通过页表可以实现**逻辑地址**到**物理地址**的[转换](#分页管理地址变换过程)。进程的各个页面是离散存在的，但页面内部是连续存放的。如果页面大小刚好是2的整数幂，则只需在页表中找到该页面对应的物理块号，再拼接上页内偏移量就能得到对应的物理地址

补充：在多个进程并发执行时，所有进程的页表大多数驻留在内存中，在系统中只设置一个页表寄存器（PTR）,它存放页表在内存中的始址和长度。平时，进程未执行时，页表的始址和页表长度存放在本进程的PCB中，当调度到某进程时，才将这两个数据装入页表寄存器中。==疑问==
   
[3.5.3 Cache 和主存的映射关系](../2%20计算机组成原理/第3章%20存储系统#3.5.3%20Cache%20和主存的映射关系)

### 基本地址变换机构

> 虚拟地址向物理地址的转换由内存映射单元 MMU 完成

![基本地址变换机构.pdf](附件/07.3.1.4_2%20基本地址变换机构.pdf)

#### 页表寄存器

基本地址变换机构可以借助进程的页表将逻辑地址转换为物理地址。

通常会在系统中设置一个**页表寄存器**(PTR)，存放页表在内存中的起始物理地址F和页表长度M。
多级页表中，页表寄存器存放的是顶级页表的起始物理地址

进程未执行时，页表的始址和页表长度放在进程控制块(PCB)中，当进程被调度时，操作系统内核会把它们放到页表寄存器中。

#### 分页管理地址变换过程

![第3章-分页存储管理的逻辑地址.drawio](图表/第3章-分页存储管理的逻辑地址.drawio.svg)

设页面大小为L，逻辑地址A到物理地址E的变换过程如下：

1. **逻辑地址A→页号P**：计算页号 $P$ 和页内偏移量 $W$ ^[注：如果用十进制数手算，则 $P=A/L$，$W=A\%L$；但是在计算机实际运行时，逻辑地址结构是固定不变的，因此计算机硬件可以更快地得到二进制表示的页号、页内偏移量]
2. **检查合法性**：比较页号 $P$ 和页表长度 $M$ ，若 $P\geqslant M$ ，则产生越界中断，否则继续执行 ^[注意：页号是从 $0$ 开始的，而页表长度至少是 $1$ ，因此 $P=M$ 时也会越界]
3. **页号P→内存块号b**：页表中页号 $P$ 对应的页表项地址=页号$P$ $\times$ 页表项长度 $+$ 页表起始地址 $F$ ，<!--算出内存块号放在哪个位置-->取出该页表项内容 $b$ ，即为内存块号。 ^[注意区分页表项长度、页表长度、页面大小的区别。页表长度指的是这个页表中总共有几个页表项，即总共有几个页；页表项长度指的是每个页表项占多大的存储空间；页面大小指的是一个页面占多大的存储空间]
4. **内存块号b→物理地址E**：计算物理地址 $E$  = 内存块号 $b$  $\times$ 页面长度 $L$  $+$ 页内偏移量 $W$ ，用得到的物理地址 $E$ 去访存。如果内存块号、页面偏移量是用二进制表示的，那么把二者拼接起来就是最终的物理地址

#### 对页表项大小的进一步探讨

可能会出现一个页面装不满页表项（即会有内存碎片），会给页表项存放地址的计算带来困扰

理论上，页表项长度为3B即可表示内存块号的范围，但是，为了方便页表的查询，实际应用中常常会让一个页表项占更多的字节，**使得每个页面恰好可以装得下整数个页表项**。

进程页表通常是装在连续的内存块中的

### 具有快表的地址变换机构

> 访问内存单元的整个过程中，需要进行两次访问内存（查询页表+实际访问）。
> 设法减少内存访问次数，加快地址访问的过程

![具有快表的地址变换机构.pdf](附件/08.3.1.4_3%20具有快表的地址变换机构.pdf)

#### 快表
> 注意联系[Cache](第3章%20存储系统#3.5%20高速缓冲存储器)

**快表**，又称联想寄存器(TLB，translation lookaside buffer)，是一种访问速度比内存快很多的[高速缓存](../2%20计算机组成原理/第3章%20存储系统#3.5%20高速缓冲存储器)（TLB不是内存！），用来存放最近访问的页表项的副本，可以加速地址变换的速度。与此对应，内存中的页表常称为**慢表**。
![第3章-TLB组成.drawio](图表/第3章-TLB的组成.drawio.svg)
注意与[Cache的结构](../2%20计算机组成原理/图表/第3章-Cache组成.drawio.svg)对比
**TLB和普通Cache的区别**——TLB中只有页表项的副本，而普通Cache中可能会有其他各种数据的副本

#### 引入快表后地址的变换过程

1. CPU给出逻辑地址，由某个硬件算得页号、页内偏移量，将页号与快表中的所有页号进行比较。
2. 如果找到匹配的页号，说明要访问的页表项在快表中有副本，则直接从中取出该页对应的内存块号，再将内存块号与页内偏移量拼接形成物理地址，最后，访问该物理地址对应的内存单元。因此，若<u>快表命中，则访问某个逻辑地址仅需一次访存即可</u>。
3. 如果没有找到匹配的页号，则需要访问内存中的页表，找到对应页表项，得到页面存放的内存块号，再将内存块号与页内偏移量拼接形成物理地址，最后，访问该物理地址对应的内存单元。因此，若快表未命中，则访问某个逻辑地址需要两次访存（注意：<u>在找到页表项后，应同时将其存入快表，以便后面可能的再次访问。</u>但若快表已满，则必须按照一定的[算法](#3.2.4%20页面置换算法)对旧的页表项进行替换）

![第3章-请求分页中的地址变换过程.drawio](图表/第3章-请求分页中的地址变换过程.drawio.svg)

由于查询快表的速度比查询页表的速度快很多，因此只要快表命中，就可以节省很多时间。因为局部性原理，一般来说快表的命中率可以达到90%以上。

#### 局部性原理

> [3.5.1 程序访问的局部性原理](../2%20计算机组成原理/第3章%20存储系统#3.5.1%20程序访问的局部性原理)

**时间局部性**：如果执行了程序中的某条指令，那么不久后这条指令很有可能再次执行；如果某个数据被访问过，不久之后该数据很可能再次被访问。（因为程序中存在大量的循环）

**空间局部性**：一旦程序访问了某个存储单元，在不久之后，其附近的存储单元也很有可能被访问。（因为很多数据在内存中都是连续存放的，并且程序的指令也是顺序地在内存中存放的）

上小节介绍的基本地址变换机构中，每次要访问一个逻辑地址，都需要查询内存中的页表。由于局部性原理，<u>可能连续很多次查到的都是同一个页表项</u>

###  两级页表


![两级页表.pdf](附件/09.3.1.4_4%20两级页表.pdf)


#### 单级页表存在的问题

* 问题一：页表必须连续存放，因此当页表很大时，需要占用很多个连续的页框。
	* 两级页表
* 问题二：没有必要让整个页表常驻内存，因为进程在一段时间内可能只需要访问某几个特定的页面。
	* 可以在需要访问页面时才把页面调入内存（[虚拟存储技术](#3.2%20虚拟内存管理)）。可以在页表项中增加一个标志位，用于表示该页面是否已经调入内存
	* 若想访问的页面不在内存中，则产生缺页中断（内中断/异常），然后将目标页面从外存调入内存

把页表再分页并离散存储，然后再建立一张页表记录页表各个部分的存放位置，称为**页目录表**，或称外层页表，或称顶层页表<!--套娃-->

#### 两级页表中的地址变换过程

![第3章-两级页表逻辑地址.drawio](图表/第3章-两级页表逻辑地址.drawio.svg)

1. 按照地址结构将逻辑地址拆分成三部分
2. 从PCB中读出页目录表始址，再根据一级页号查页目录表，找到下一级页表在内存中的存放位置
3. 根据二级页号查二级页表，找到最终想访问的内存块号
4. 结合页内偏移量得到物理地址

#### 需要注意的细节

* TLB命中后不会缺页，TLB不会因为二级页表而拆分
* 若分为两级页表后，页表依然很长，则可以采用更多级页表，一般来说各级页表的大小不能超过一个页面（每级页号不超过10位）
* 两级页表的访存次数分析（假设没有快表机构）
	* 第一次访存：访问内存中的页目录表
	* 第二次访存：访问内存中的二级页表
	* 第三次访存：访问目标内存单元

![第3章-部分概念间的关系.drawio](图表/第3章-部分概念间的关系.drawio.svg)

> 可参考2020年真题第46题进行学习

## 3.1.5 基本分段存储管理

> 与“分页”的最大区别就是离散分配时所分配的地址空间的基本单位不同
>

![基本分段存储管理方式.pdf](附件/10.3.1.5%20基本分段存储管理方式.pdf)


### 分段

进程的地址空间：按照程序**自身的逻辑关系**划分为若干个段，每个段都有一个段名（在低级语言中，程序员使用段名来编程），每段从0开始编址

内存分配规则：<u>以段为单位进行分配，每个段在内存中占据连续空间，但各段之间可以不相邻。</u>

由于是按逻辑功能模块划分，用户编程更方便，程序的可读性更高

分段系统的逻辑地址结构由**段号**（段名）和**段内地址**（段内偏移量）所组成。编译程序会将段名翻译为段号，用助记符表示的内存单元会被翻译为段内地址
* 段号的位数决定了每个进程最多可以分几个段
* 段内地址位数决定了每个段的最大长度是多少

### 段表

程序分多个段，各段离散地装入内存，为了保证程序能正常运行，就必须能从物理内存中找到各个逻辑段的存放位置。为此，需为每个进程建立一张段映射表，简称“**段表**”。<!--类似页表-->

* 每个段对应一个段表项，其中记录了该段在内存中的起始位置（又称“**基址**”）和**段的长度**。
* 各个段表项的长度是相同的。例如：某系统按字节寻址，采用分段存储管理，逻辑地址结构为（段号16位,段内地址16位），因此用16位即可表示最大段长。物理内存大小为4GB（可用32位表示整个物理内存地址空间）。因此，可以让每个段表项占16+32 = 48位，即6B。
* 由于段表项长度相同，因此<u>段号可以是隐含</u>的，不占存储空间。若段表存放的起始地址为M，则K号段对应的段表项存放的地址为M + K\*6

### 分段管理地址变换过程

与分页管理相比，需要检查段内地址是否超过段长。

1. 由逻辑地址得到段号、段内地址
2. 段号与段表寄存器中的段长度比较，检查是否越界
3. 由段表始址、段号找到对应段表项
4. 根据段表中记录的段长，<u>检查段内地址是否越界</u>
5. 由段表中的“基址+段内地址”得到最终的物理地址
6. 访问目标单元

### 分段、分页管理对比

* **页是信息的物理单位**。分页的主要目的是为了实现离散分配，提高内存利用率。分页仅仅是系统管理上的需要，完全是系统行为，<u>对用户是不可见的</u>。
  **段是信息的逻辑单位**。分段的主要目的是更好地满足用户需求。一个段通常包含着一组属于一个逻辑模块的信息。<u>分段对用户是可见的</u>，用户编程时需要显式地给出段名。
* 页的大小固定且由系统决定。段的长度却不固定，决定于用户编写的程序。
  分页的用户进程地址空间是一维的，程序员只需给出一个记忆符即可表示一个地址。
  分段的用户进程地址空间是二维的，程序员在标识一个地址时，既要给出段名，也要给出段内地址
* 分段比分页更容易实现信息的共享和保护。
  只需让各进程的段表项指向同一段即可实现共享
  不能被修改的代码称为**纯代码或可重入代码**（不属于临界资源），这样的代码是可以共享的。
  可修改的代码是不能共享的（比如，有一个代码段中有很多变量，各进程并发地同时访问可能造成数据不一致）

## 3.1.6 段页式管理

> 分段+分页的结合——段页式管理

![段页式管理方式.pdf](附件/11.3.1.6%20段页式管理方式.pdf)

### 分页、分段的优缺点

|          | 优点                                                     | 缺点                                                         |
| -------- | -------------------------------------------------------- | ------------------------------------------------------------ |
| 分页管理 | 内存空间利用率高，不会产生外部碎片，只会有少量的页内碎片 | 不方便按照逻辑模块实现信息的共享和保护                       |
| 分段管理 | 很方便按照逻辑模块实现信息的共享和保护                   | 如果段长过大，为其分配很大的连续空间会很不方便；另外，段式管理会产生外部碎片 |

### 段页式管理

将进程按逻辑模块分段，再将各段分页（如每个页面4KB），再将内存空间分为大小相同的内存块/页框/页帧/物理块
进程前将各页面分别装入各内存块中

逻辑地址=段号+<u>页号+页内偏移量</u>* 分段比分页更容易实现信息的共享和保护。
* 段号的位数决定了每个进程最多可以分几个段
* 页号位数决定了每个段最大有多少页
* 页内偏移量决定了页面大小、内存块大小是多少

“分段”对用户是可见的，程序员编程时需要显式地给出段号、段内地址。而将各段“分页”对用户是不可见的。系统会根据段内地址自动划分页号和页内偏移量。因此<u>段页式管理的地址结构是二维的。</u>

### 段表、页表

段表：每个段对应一个段表项，每个段表项由段号、<u>页表长度、页表存放块号（页表起始地址）</u>组成。每个段表项长度相等，段号是隐含的。

页表：每个页面对应一个页表项，每个页表项由页号、页面存放的内存块号组成。每个页表项长度相等，页号是隐含的。

### 段页式管理地址变换过程

1. 由逻辑地址得到段号、页号、页内偏移量
2. 段号与段表寄存器中的段长度比较，检查是否越界
3. 由段表始址、段号找到对应段表项
4. 根据段表中记录的页表长度，检查页号是否越界
5. 根据段表中的页表地址、页号查询页表，找到相应表项
6. 由页面存放的内存块号、业内偏移量得到最终的物理地址
7. 访问目标单元

## 3.1.8 本节习题精选

**选择题**：[题目](王道操作系统.pdf#page=187&selection=564,0,567,1)、[答案](王道操作系统.pdf#page=195&selection=321,0,326,1)

**综合题**：[题目](王道操作系统.pdf#page=193&selection=10,0,14,2)、[答案](王道操作系统.pdf#page=201&selection=677,0,681,2)

# 3.2 虚拟内存管理

## 3.2.1 虚拟内存的基本概念


![虚拟内存的基本概念.pdf](附件/01.3.2.1%20虚拟内存的基本概念.pdf)


### 传统存储管理方式的特征、缺点

* **一次性**：作业必须一次性全部装入内存后才能开始运行。这会造成两个问题：①作业很大时，不能全部装入内存，导致大作业无法运行；②当大量作业要求运行时，由于内存无法容纳所有作业，因此只有少量作业能运行，导致多道程序并发度下降。
* **驻留性**：一旦作业被装入内存，就会一直驻留在内存中，直至作业运行结束。事实上，在一个时间段内，只需要访问作业的一小部分数据即可正常运行，这就导致了内存中会驻留大量的、暂时用不到的数据，浪费了宝贵的内存资源。

### 虚拟内存的定义和特征

* 基于[局部性原理](#局部性原理)，在程序装入时，可以<u>将程序中很快会用到的部分装入内存，暂时用不到的部分留在外存</u>，就可以让程序开始执行。
* 在程序执行过程中，<u>当所访问的信息不在内存时，由操作系统负责将所需信息从外存调入内存</u>，然后继续执行程序。
* <u>若内存空间不够，由操作系统负责将内存中暂时用不到的信息换出到外存</u>。
* 在操作系统的管理下，在用户看来似乎有一个比实际内存大得多的内存，这就是**虚拟内存**

虚拟内存有以下三个主要特征：

* **多次性**：无需在作业运行时一次性全部装入内存，而是允许被分成多次调入内存。
* **对换性**：在作业运行时无需一直常驻内存，而是允许在作业运行过程中，将作业换入、换出。
* **虚拟性**：从逻辑上扩充了内存的容量，使用户看到的内存容量，远大于实际的容量。

### 如何实现虚拟内存技术

虚拟内存技术，允许一个作业分多次调入内存。如果采用连续分配方式，会不方便实现。因此，<u>虚拟内存的实现需要建立在离散分配的内存管理方式基础上。</u>

* [基本分页存储管理](#3.1.4%20基本分页存储管理)→[3.2.2 请求分页管理方式](#3.2.2%20请求分页管理方式)
* [基本分段存储管理](#3.1.5%20基本分段存储管理)→请求分段存储管理
* [基本段页式存储管理](#3.1.6%20段页式管理)→请求段页式存储管理

主要区别：

* 请求调页/段功能：在程序执行过程中，当所访问的信息不在内存时，由操作系统负责将所需信息从外存调入内存，然后继续执行程序。
* 页面/段置换功能：若内存空间不够，由操作系统负责将内存中暂时用不到的信息换出到外存。

## 3.2.2 请求分页管理方式


![请求分页管理方式.pdf](附件/02.3.2.2%20请求分页管理方式.pdf)


### 页表机制

* **请求调页功能**：与[基本分页管理](#3.1.4%20基本分页存储管理)相比，请求分页管理中，为了实现“请求调页”，操作系统需要知道每个页面是否已经调入内存；如果还没调入，那么也需要知道该页面在外存中存放的位置。
* **页面置换功能**：当内存空间不够时，要实现“页面置换”，操作系统需要通过某些指标来决定到底换出哪个页面；有的页面没有被修改过，就不用再浪费时间写回外存。有的页面修改过，就需要将外存中的旧数据覆盖，因此，操作系统也需要记录各个页面是否被修改的信息。

![第3章-请求分页系统中的页表项.drawio](图表/第3章-请求分页系统中的页表项.drawio.svg)

* 状态位P：（合法位、有效位）是否已调入内存，供程序访问时参考
* 访问字段A：可记录最近被访问过几次，或记录上次访问的时间，供置换算法选择换出页面时参考
* 修改位M：（脏位）标识页面调入内存后是否被修改过，只有修改过的页面才需要在置换时写回外存
* 外存地址：指出页面在外存中的存放位置，通常是物理块号，供调入该页时参考<!--注意是外存地址不是主存的物理地址-->

### 缺页中断机构

在请求分页系统中，每当要访问的页面不在内存时，便产生一个缺页中断，然后由操作系统的缺页中断处理程序处理中断。此时缺页的进程阻塞，放入阻塞队列，调页完成后再将其唤醒，放回就绪队列。

* 如果内存中有空闲块，则为进程分配一个空闲块，将所缺页面装入该块，并修改页表中相应的页表项。
* 如果内存中没有空闲块，则由页面置换算法选择一个页面淘汰，若该页面在内存期间被修改过，则要将其写回外存。未修改过的页面不用写回外存。

缺页中断是因为当前执行的指令想要访问的目标页面未调入内存而产生的，因此属于[**内中断**](第1章%20计算机系统概述#内中断)
<u>一条指令在执行期间，可能产生多次缺页中断。</u>（如：`copy A to B`，即将逻辑地址A中的数据复制到逻辑地址B，而A、B属于不同的页面，则有可能产生两次中断）

### 请求分页地址变换过程

* 新增步骤1：请求调页（查到页表项时进行判断）
* 新增步骤2：页面置换（需要调入页面，但没有空闲内存块时进行）
* 新增步骤3：需要修改请求页表中新增的表项

## 3.2.4 页面置换算法


![页面置换算法.pdf](附件/03.3.2.4%20页面置换算法.pdf)


页面的换入、换出需要磁盘I/O，会有较大的开销，因此好的页面置换算法应该追求更少的缺页率

### 最佳置换算法(OPT)

最佳置换算法(OPT，Optimal)：<u>每次选择淘汰的页面将是以后永不使用，或者在最长时间内不再被访问的页面</u>，这样可以保证最低的缺页率

最佳置换算法可以保证最低的缺页率，但实际上，只有在进程执行的过程中才能知道接下来会访问到的是哪个页面。操作系统无法提前预判页面访问序列。因此，最佳置换算法是无法实现的。

访问页面|7|0|1|2|0|3|0|4|2|3|0|3|2|1|2|0|1|7|0|1
:--:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:
内存块1|**7**|7|7|**2**| |2| |2| | |2| | |2| | | |**7**| |
内存块2| |**0**|0|0| |0| |**4**| | |**0**| | |0| | | |0| |
内存块3| | |**1**|1| |**3**| |3| | |3| | |**1**| | | |1| |
是否缺页|√|√|√|√| |√| |√| | |√| | |√| | | |√| |

### 先进先出页面置换算法(FIFO)

先进先出置换算法(FIFO）：<u>每次选择淘汰的页面是最早进入内存的页面</u>
实现方法：把调入内存的页面根据调入的先后顺序排成一个队列，需要换出页面时选择队头页面即可。队列的最大长度取决于系统为进程分配了多少个内存块。

| 访问页面 |   3   |   2   |   1   |   0   |   3   |   2   |   4   |  3   |  2   |   1   |   0   |  4   |
| :------: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :--: | :--: | :---: | :---: | :--: |
| 内存块1  | **3** |   3   |   3   | **0** |   0   |   0   | **4** |      |      |   4   |   4   |      |
| 内存块2  |       | **2** |   2   |   2   | **3** |   3   |   3   |      |      | **1** |   1   |      |
| 内存块3  |       |       | **1** |   1   |   1   | **2** |   2   |      |      |   2   | **0** |      |
| 是否缺页 |   √   |   √   |   √   |   √   |   √   |   √   |   √   |      |      |   √   |   √   |      |

**Belady异常**——当为进程分配的物理块数增大时，缺页次数不减反增的异常现象。

> 对于FIFO算法来说，在同一时刻，使用4个页框时缓存中保存的页面并不完全包含使用3个页框时保存的页面，<u>二者不是超集子集关系</u>，造成都某些特殊的页面请求序列，4个页框命中率反而低。

| 访问页面 |   3   |   2   |   1   |   0   |  3   |  2   |   4   |   3   |   2   |   1   |   0   |   4   |
| :------: | :---: | :---: | :---: | :---: | :--: | :--: | :---: | :---: | :---: | :---: | :---: | :---: |
| 内存块1  | **3** |   3   |   3   |   3   |      |      | **4** |   4   |   4   |   4   | **0** |   0   |
| 内存块2  |       | **2** |   2   |   2   |      |      |   2   | **3** |   3   |   3   |   3   | **4** |
| 内存块3  |       |       | **1** |   1   |      |      |   1   |   1   | **2** |   2   |   2   |   2   |
| 内存块4  |       |       |       | **0** |      |      |   0   |   0   |   0   | **1** |   1   |   1   |
| 是否缺页 |   √   |   √   |   √   |   √   |      |      |   √   |   √   |   √   |   √   |   √   |   √   |


只有FIFO算法会产生Belady异常。另外，FIFO算法虽然实现简单，但是该算法与进程实际运行时的规律（局部性）不适应，因为先进入的页面也有可能最经常被访问。因此，算法性能差

### 最近最久未使用置换算法(LRU)

最近最久未使用置换算法(LRU，least recently used）：<u>每次淘汰的页面是最近最久未使用的页面</u>

实现方法：赋予每个页面对应的页表项中，用访问字段记录该页面自上次被访问以来所经历的时间 $t$ 。当需要淘汰一个页面时，选择现有页面中 $t$ 值最大的，即最近最久未使用的页面。

实现需要专门的硬件支持，虽然算法性能好，但是实现困难，开销大

|访问页面|7|0|1|2|0|3|0|4|2|3|0|3|2|1|2|0|1|7|0|1|
|:------:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|
|内存块1|**7**|7|7|**2**| |2| |**4**|4|4|**0**| | |**1**| |1| |1| ||
|内存块2| |**0**|0|0| |0| |0|0|**3**|3| | |3| |**0**| |0| ||
|内存块3| | |**1**|1| |**3**| |3|**2**|2|2| | |2| |2| |**7**| ||
|是否缺页|√|√|√|√| |√| |√|√|√|√| | |√| |√| |√| ||

手动做题时，若要淘汰页面，可以逆向检查此时在内存中的几个页面号。在逆向扫描过程中最后一个出现的页号就是要淘汰的页面
### 时钟置换算法(CLOCK)

> 最佳置换算法性能最好，但无法实现；
> 先进先出置换算法实现简单，但算法性能差；
> 最近最久未使用置换算法性能好，是最接近OPT算法性能的，但是实现起来需要专门的硬件支持，算法开销大。

时钟置换算法是一种性能和开销较均衡的算法，又称CLOCK算法，或**最近未用算法**(NRU, Not Recently Used）

简单的CLOCK算法实现方法：为每个页面设置一个**访问位**，再将内存中的页面都通过链接指针链接成一个循环队列。<u>当某页被访问时，其访问位置为1</u>。当需要淘汰一个页面时，只需检查页的访问位。<u>如果是0，就选择该页换出；如果是1，则将它置为0，暂不换出，继续检查下一个页面</u>，若第一轮扫描中所有页面都是1，则将这些页面的访问位依次置为0后，再进行第二轮扫描（第二轮扫描中一定会有访问位为0的页面，因此<u>简单的CLOCK算法选择一个淘汰页面最多会经过两轮扫描</u>）

**例题**：假设系统为某进程分配了五个内存块，并考虑到有以下页面号引用串：$1,3,4,2,5,6,3,4,7$。

+ 首先第一步，由于有五个内存块，所以前五个页面全部正常进入，将$1,3,4,2,5$链接成为循环队列，代表置入内存的内存块，此时访问位全部为$1$，表示全部被访问并置入内存。
+ 然后访问到$6$，需要置换出一个页面，所以循环访问块链，由于都访问过，所以扫描指针依次扫描$1,3,4,2,5$，将访问位全部改为$0$。
+ 第二轮循环开始，扫描指针指向第一个的$1$访问位为$0$，则将$1$换出，$6$换入，访问位置为$1$，变为$6,3,4,2,5$，扫描指针指向$3$。
+ 接着访问指针转动，访问$3$和$4$，由于都在链中，所以将其访问位都置为$1$。
+ 访问指针指向是$7$，因为$7$不在内存中，需要换出页面。
+ 扫描指针从上次的$3$开始扫描，$3$、$4$访问位为$1$，而$2$访问位为$0$，所以$7$换入$2$换出，$7$的访问位置为$1$，变为$6,3,4,7,5$，扫描指针指向$5$。
+ 访问结束。

### 改进型时钟置换算法

简单的时钟置换算法仅考虑到一个页面最近是否被访问过。事实上，如果被淘汰的页面没有被修改过，就不需要执行I/O操作写回外存。只有被淘汰的页面被修改过时，才需要写回外存。因此，除了考虑一个页面最近有没有被访问过之外，操作系统还应考虑页面有没有被修改过。<u>在其他条件都相同时，应优先淘汰没有修改过的页面，避免I/O操作。</u>这就是改进型的时钟置换算法的思想。

修改位=0，表示页面没有被修改过；修改位=1，表示页面被修改过。为方便讨论，用 **(访问位, 修改位)** 的形式表示各页面状态。如(1,1)表示一个页面近期被访问过，且被修改过。

算法规则：将所有可能被置换的页面排成一个循环队列

1. 第一轮：从当前位置开始扫描到第一个(0, 0)的帧用于替换。本轮扫描不修改任何标志位
 > 第一优先级：最近没有被访问且没有修改的页面
2. 第二轮：若第一轮扫描失败，则重新扫描，查找第一个(0, 1)的帧用于替换。本轮将所有扫描过的帧访问位设为0
 > 第二优先级：最近没有被访问但被修改过的页面
3. 第三轮：若第二轮扫描失败，则重新扫描，查找第一个(0, 0)的帧用于替换。本轮扫描不修改任何标志位
 > 第三优先级：最近访问过，但没有修改的页面
4. 第四轮：若第三轮扫描失败，则重新扫描，查找第一个(0, 1)的帧用于替换。
 > 第四优先级：最近访问过，而且被修改过的页面

由于第二轮已将所有帧的访问位设为0，因此经过第三轮、第四轮扫描一定会有一个帧被选中，因此<u>改进型CLOCK置换算法选择一个淘汰页面最多会进行四轮扫描</u>

## 3.2.3 页框分配


![页面分配策略.pdf](附件/04.3.2.5+3.2.3%20页面分配策略.pdf)

### 驻留集

**驻留集**：指请求分页存储管理中给进程分配的物理块的集合。在采用了虚拟存储技术的系统中，驻留集大小一般小于进程的总大小。

* 若驻留集太小，会导致缺页频繁，系统要花大量的时间来处理缺页，实际用于进程推进的时间很少；
* 驻留集太大，又会导致多道程序并发度下降，资源利用率降低。所以应该选择一个合适的驻留集大小。

驻留集的大小是否可变

* **固定分配**：操作系统为每个进程分配一组固定数目的物理块，在进程运行期间不再改变。即，驻留集大小不变
* **可变分配**：先为每个进程分配一定数目的物理块，在进程运行期间，可根据情况做适当的增加或减少。即，驻留集大小可变

页面的置换范围

* **局部置换**：发生缺页时只能选进程自己的物理块进行置换。
* **全局置换**：可以将操作系统保留的空闲物理块分配给缺页进程，也可以将别的进程持有的物理块置换到外存，再分配给缺页进程。

### 内存分配策略

> 全局置换意味着一个进程拥有的物理块数量必然会改变，因此不可能是固定分配

![第3章-内存分配策略.drawio](图表/第3章-内存分配策略.drawio.svg)

#### 固定分配局部置换

系统为每个进程分配一定数量的物理块，在整个运行期间都不改变。若进程在运行中发生缺页，则只能从该进程在内存中的页面中选出一页换出，然后再调入需要的页面。

这种策略的缺点是：很难在刚开始就确定应为每个进程分配多少个物理块才算合理。（采用这种策略的系统可以根据进程大小、优先级、或是根据程序员给出的参数来确定为一个进程分配的内存块数）

#### 可变分配全局置换
> 只要缺页就分配新的物理块

刚开始会为每个进程分配一定数量的物理块。操作系统会保持一个空闲物理块队列。当某进程发生缺页时，从空闲物理块中取出一块分配给该进程；若已无空闲物理块，则可选择一个<u>未锁定的页面换出外存</u>，再将该物理块分配给缺页的进程。

采用这种策略时，<u>只要某进程发生缺页，都将获得新的物理块</u>，仅当空闲物理块用完时，系统才选择一个未锁定的页面调出。被选择调出的页可能是系统中任何一个进程中的页，因此这个被选中的进程拥有的物理块会减少，缺页率会增加。

#### 可变分配局部置换
> 根据缺页率动态调整进程的物理块

刚开始会为每个进程分配一定数量的物理块。当某进程发生缺页时，只允许从该进程自己的物理块中选出一个进行换出外存。

<u>根据发生缺页的频率来动态地增加或减少进程的物理块</u>：如果进程在运行中频繁地缺页，系统会为该进程多分配几个物理块，直至该进程缺页率趋势适当程度；反之，如果进程在运行中缺页率特别低，则可适当减少分配给该进程的物理块。

### 何时调入页面

* **预调页策略**：根据局部性原理，一次调入若干个相邻的页面可能比一次调入一个页面更高效。但如果提前调入的页面中大多数都没被访问过，则又是低效的。因此可以<u>预测不久之后可能访问到的页面，将它们预先调入内存</u>，但目前预测成功率只有50%左右。故这种策略主要用于进程的首次调入，由程序员指出应该先调入哪些部分。
* **请求调页策略**：<u>进程在运行期间发现缺页时才将所缺页面调入内存。</u>由这种策略调入的页面一定会被访问到，但由于每次只能调入一页，而每次调页都要磁盘I/O操作，因此I/O开销较大。

### 从何处调入页面

* 若**系统拥有足够的对换区空间**：页面的调入、调出都是在内存与对换区之间进行，这样可以保证页面的调入、调出速度很快。在进程运行前，需将进程相关的数据从文件区复制到对换区。
* 若**系统缺少足够的对换区空间**：凡是不会被修改的数据都直接从文件区调入，由于这些页面不会被修改，因此换出时不必写回磁盘，下次需要时再从文件区调入即可。对于可能被修改的部分，换出时需写回磁盘对换区，下次需要时再从对换区调入。
* **UNIX方式**：运行之前进程有关的数据全部放在文件区，故未使用过的页面，都可从文件区调入。若被使用过的页面需要换出，则写回对换区，下次需要时从对换区调入。

## 3.2.5 抖动和工作集

### 抖动

刚刚换出的页面马上又要换入内存，刚刚换入的页面马上又要换出外存，这种频繁的页面调度行为称为**抖动**，或**颠簸**。产生抖动的主要原因是进程频繁访问的页面数目高于可用的物理块数（分配给进程的物理块不够）

* 为进程分配的物理块太少，会使进程发生抖动现象；
* 为进程分配的物理块太多，又会降低系统整体的并发度，降低某些资源的利用率

### 工作集
> 为了研究为应该为每个进程分配多少个物理块，Denning提出了进程“工作集”的概念

* **驻留集**：指请求分页存储管理中给进程分配的内存块的集合。
* **工作集**：指在某段时间间隔里，进程实际访问页面的集合。

<u>操作系统会根据**窗口尺寸**来确定工作集</u>，即窗口中内存访问过的页面个数即为工作集。

<u>工作集大小可能小于窗口尺寸</u>，实际应用中，操作系统可以统计进程的工作集大小，<u>根据工作集大小来确定驻留集大小</u>，即确定给进程的内存块个数。如：窗口尺寸为5，经过一段时间的监测发现某进程的工作集最大为3，那么说明该进程有很好的局部性，可以给这个进程分配3个以上的内存块（驻留集）即可满足进程的运行需要。

一般来说，驻留集大小不能小于工作集大小，否则进程运行过程中将频繁缺页。

拓展：基于局部性原理可知，进程在一段时间内访问的页面与不久之后会访问的页面是有相关性的。因此，可以根据进程近期访问的页面集合（工作集）来设计一种页面置换算法——选择一个不在工作集中的页面进行淘汰。

## 3.2.6 内存映射文件


![内存映射文件.pdf](附件/05.3.2.6%20内存映射文件.pdf)


传统的文件访问方式：

1. `open`系统调用——打开文件
2. `seek`系统调用——将读写指针移到某个位置
3. `read`系统调用——从读写指针所指位置读入若干数据（从磁盘读入内存）
4. `write`系统调用——将内存中的指定数据，写回磁盘（根据读写指针确定要写回什么位置）

内存映射文件的访问方式

1. `open`系统调用——打开文件
2. `mmap`系统调用——将文件映射到进程的虚拟地址空间
3. `close`系统调用——关闭文件

* 以访问内存的方式访问文件数据
* 文件数据的读入、写出由操作系统自动完成
* 进程关闭文件时，操作系统自动将文件被修改的数据写回磁盘

![第3章-内存映射IO的共享内存.drawio](图表/第3章-内存映射IO的共享内存.drawio.svg)

**内存映射文件**——操作系统向上层程序员提供的功能（系统调用）

* 方便程序员访问文件数据
* 方便多个进程共享同一个文件

特性

* 进程可以使用系统调用，请求操作系统将文件映射到进程的虚拟地址空间
* 以访问内存的方式读写文件
* 进程关闭文件时，操作系统负责将文件数据写回磁盘，并解除内存映射
* 多个进程可以映射同一个文件，方便共享

优点

* 程序员编程更简单，已建立映射的文件，只需要按访问内存的方式读写即可
* 文件数据的读入/读出完全由操作系统负责，I/O效率可以由操作系统负责优化（如预读入、缓写出等）

## 3.2.7 虚拟存储器性能影响因素

==暂缺==

**缺页率**是影响虚拟存储器性能的主要因素，且缺页率受到页面大小、分配给进程的物理块数、页面置换算法以及程序的编制方法的影响

从实际使用来说，虚拟存储器能使得进程的可用内存扩大到内外存容量之和，但进程的内存寻址仍由计算机的地址结构决定，这就决定了虚拟存储器理论上的最大容量。例如：地址寄存器有32位，则虚拟存储器的最大容量为 $2^{32}$B

## 3.2.8 地址翻译

## 3.2.10 本节习题精选

**选择题**：[题目](王道操作系统.pdf#page=218&selection=784,0,789,1)、[答案](王道操作系统.pdf#page=228&selection=59,0,64,1)

**综合题**：[题目](王道操作系统.pdf#page=223&selection=75,0,80,2)、[答案](王道操作系统.pdf#page=232&selection=699,0,704,2)
